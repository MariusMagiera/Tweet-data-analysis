{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JSON;\n",
    "using DataFrames;\n",
    "using CSV;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read JSON file, create Dataframe and learn to access it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.384163 seconds (1.50 M allocations: 121.597 MiB, 27.12% gc time)\n"
     ]
    }
   ],
   "source": [
    "# read the JSON file line by line \n",
    "p = \"coronavirus-tweet-id-2020-01-22-06-11.json\"\n",
    "@time jsons = open(p) do io\n",
    "    JSON.parse.(eachline(io))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of keys \n",
    "tweet_keys = []\n",
    "for key in keys(jsons[1])\n",
    "    push!(tweet_keys, key)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_tweet (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a clean tweet object extracts and contains the following attributes from the raw tweet: \n",
    "# the original tweet's : id, created at, user, language text\n",
    "\n",
    "# if the tweet is a retweet, our object also contains the retweet's: rt_text, rt_user, rt_id, rt_lang\n",
    "# along with a boolean value is_rt that indicates whether the current tweet is a retweet. \n",
    "\n",
    "function clean_tweet(jsons)\n",
    "    IDs = []\n",
    "    created_at = []\n",
    "    user_names = []\n",
    "    hashtags = []\n",
    "\n",
    "\n",
    "    retweeted_status = [] \n",
    "    rt_user = [] \n",
    "    rt_id = []\n",
    "\n",
    "    for i in 1:length(jsons)\n",
    "        push!(IDs, jsons[i][\"id\"])\n",
    "        push!(created_at, jsons[i][\"created_at\"])\n",
    "        push!(user_names, jsons[i][\"user\"][\"screen_name\"])\n",
    "        \n",
    "        #check if retweeted \n",
    "        if haskey(jsons[i], \"retweeted_status\")\n",
    "            push!(retweeted_status, true)\n",
    "            \n",
    "            # if there are hashtags, push them \n",
    "            if length(jsons[i][\"retweeted_status\"][\"entities\"][\"hashtags\"]) != 0\n",
    "                # read all hashtags and safe in temp_hashs\n",
    "                temp_hashs = []\n",
    "                for j in 1:length(jsons[i][\"retweeted_status\"][\"entities\"][\"hashtags\"])\n",
    "                    push!(temp_hashs,jsons[i][\"retweeted_status\"][\"entities\"][\"hashtags\"][j][\"text\"])\n",
    "                end\n",
    "                # push hashtags into hashtag array \n",
    "                push!(hashtags,temp_hashs)\n",
    "            else \n",
    "                push!(hashtags,0)\n",
    "            end\n",
    "                    \n",
    "            # original Tweeter \n",
    "            push!(rt_user, jsons[i][\"retweeted_status\"][\"user\"][\"screen_name\"])\n",
    "            push!(rt_id, jsons[i][\"retweeted_status\"][\"id\"])\n",
    "            \n",
    "        # if it wasn't a retweet\n",
    "        else\n",
    "            \n",
    "            # if there are hashtags, push them \n",
    "            if length(jsons[i][\"entities\"][\"hashtags\"]) != 0\n",
    "                temp_hashs = []\n",
    "                for j in 1:length(jsons[i][\"entities\"][\"hashtags\"])\n",
    "                    push!(temp_hashs,jsons[i][\"entities\"][\"hashtags\"][j][\"text\"])\n",
    "                end\n",
    "                push!(hashtags,temp_hashs)\n",
    "            else \n",
    "                push!(hashtags,0)\n",
    "            end\n",
    "            \n",
    "            push!(retweeted_status, false)\n",
    "            push!(rt_user, 0)\n",
    "            push!(rt_id, 0)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return IDs , created_at, user_names, retweeted_status, rt_user,  rt_id, hashtags\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.118989 seconds (81.44 k allocations: 4.125 MiB)\n"
     ]
    }
   ],
   "source": [
    "#Filter relevant information via clean_tweet() function\n",
    "@time IDs , created_at, user_names, retweeted_status, rt_user,  rt_id, hashtags = clean_tweet(jsons);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame with all wanted information\n",
    "df = DataFrame(ID = IDs[1:length(IDs)], Created_at = created_at[1:length(created_at)],USER = user_names[1:length(user_names)], Is_Retweet = retweeted_status[1:length(retweeted_status)], RT_User = rt_user[1:length(rt_user)], RT_Id = rt_id[1:length(rt_id)], Hashtags = hashtags[1:length(hashtags)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of first tweet: Wed Jan 22 06:27:54 +0000 2020\n"
     ]
    }
   ],
   "source": [
    "# Examples for how to access the df (time is not ordered yet -> see below)\n",
    "println(\"Time of first tweet: \",df.Created_at[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets in total: 2847\n"
     ]
    }
   ],
   "source": [
    "# Number of Tweets in time period\n",
    "println(\"Tweets in total: \", length(df.Hashtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ExampleCSV.csv\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write df into CSV\n",
    "CSV.write(\"ExampleCSV.csv\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ID</th><th>Created_at</th><th>USER</th><th>Is_Retweet</th></tr><tr><th></th><th>Int64</th><th>String</th><th>String</th><th>Bool</th></tr></thead><tbody><p>2,847 rows × 7 columns (omitted printing of 3 columns)</p><tr><th>1</th><td>1219869278574387200</td><td>Wed Jan 22 06:27:54 +0000 2020</td><td>UsaCleanup</td><td>true</td></tr><tr><th>2</th><td>1219871372182245400</td><td>Wed Jan 22 06:36:13 +0000 2020</td><td>innovationville</td><td>false</td></tr><tr><th>3</th><td>1219875910641488000</td><td>Wed Jan 22 06:54:15 +0000 2020</td><td>HelsinkiOne</td><td>false</td></tr><tr><th>4</th><td>1219867508041105400</td><td>Wed Jan 22 06:20:52 +0000 2020</td><td>ivona_11</td><td>true</td></tr><tr><th>5</th><td>1219868124633190400</td><td>Wed Jan 22 06:23:19 +0000 2020</td><td>sarahderpy</td><td>true</td></tr><tr><th>6</th><td>1219872204571259000</td><td>Wed Jan 22 06:39:32 +0000 2020</td><td>Frankdiplomat</td><td>false</td></tr><tr><th>7</th><td>1219871769269547000</td><td>Wed Jan 22 06:37:48 +0000 2020</td><td>evaArtemise97</td><td>false</td></tr><tr><th>8</th><td>1219871144649556000</td><td>Wed Jan 22 06:35:19 +0000 2020</td><td>Johanisms</td><td>true</td></tr><tr><th>9</th><td>1219872618787946500</td><td>Wed Jan 22 06:41:11 +0000 2020</td><td>RedMystique</td><td>true</td></tr><tr><th>10</th><td>1219874436544811000</td><td>Wed Jan 22 06:48:24 +0000 2020</td><td>psybrspcsuprstr</td><td>true</td></tr><tr><th>11</th><td>1219868954887254000</td><td>Wed Jan 22 06:26:37 +0000 2020</td><td>gingin21</td><td>true</td></tr><tr><th>12</th><td>1219868329738932200</td><td>Wed Jan 22 06:24:08 +0000 2020</td><td>Amsterdam2030</td><td>true</td></tr><tr><th>13</th><td>1219876426071052300</td><td>Wed Jan 22 06:56:18 +0000 2020</td><td>DOCisChief</td><td>false</td></tr><tr><th>14</th><td>1219868138197487600</td><td>Wed Jan 22 06:23:22 +0000 2020</td><td>BiteOfAMosquito</td><td>true</td></tr><tr><th>15</th><td>1219874441200455700</td><td>Wed Jan 22 06:48:25 +0000 2020</td><td>wholesomebutter</td><td>true</td></tr><tr><th>16</th><td>1219872782118457300</td><td>Wed Jan 22 06:41:50 +0000 2020</td><td>FlatplaneJayne</td><td>true</td></tr><tr><th>17</th><td>1219870288621342700</td><td>Wed Jan 22 06:31:55 +0000 2020</td><td>STD_Jonathan</td><td>true</td></tr><tr><th>18</th><td>1219873889896915000</td><td>Wed Jan 22 06:46:14 +0000 2020</td><td>GadflySquared</td><td>true</td></tr><tr><th>19</th><td>1219869064732008400</td><td>Wed Jan 22 06:27:03 +0000 2020</td><td>ParaSeoul</td><td>true</td></tr><tr><th>20</th><td>1219871720561107000</td><td>Wed Jan 22 06:37:36 +0000 2020</td><td>BOSSleidyx3</td><td>true</td></tr><tr><th>21</th><td>1219869917203325000</td><td>Wed Jan 22 06:30:27 +0000 2020</td><td>akuma_river</td><td>false</td></tr><tr><th>22</th><td>1219873652780556300</td><td>Wed Jan 22 06:45:17 +0000 2020</td><td>MountAirMedia</td><td>true</td></tr><tr><th>23</th><td>1219867554451284000</td><td>Wed Jan 22 06:21:03 +0000 2020</td><td>999Hawks</td><td>true</td></tr><tr><th>24</th><td>1219872044302684200</td><td>Wed Jan 22 06:38:54 +0000 2020</td><td>AnnMarieMck</td><td>true</td></tr><tr><th>25</th><td>1219868889032593400</td><td>Wed Jan 22 06:26:21 +0000 2020</td><td>jolenedurbin</td><td>false</td></tr><tr><th>26</th><td>1219868004269338600</td><td>Wed Jan 22 06:22:50 +0000 2020</td><td>DarlinNathaniel</td><td>false</td></tr><tr><th>27</th><td>1219874488227070000</td><td>Wed Jan 22 06:48:36 +0000 2020</td><td>BarbaraEEllison</td><td>false</td></tr><tr><th>28</th><td>1219869910580519000</td><td>Wed Jan 22 06:30:25 +0000 2020</td><td>MrBenDover5</td><td>true</td></tr><tr><th>29</th><td>1219870503315230700</td><td>Wed Jan 22 06:32:46 +0000 2020</td><td>mandy77975978</td><td>true</td></tr><tr><th>30</th><td>1219870616590999600</td><td>Wed Jan 22 06:33:13 +0000 2020</td><td>Roderic20444823</td><td>true</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& ID & Created\\_at & USER & Is\\_Retweet & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & String & Bool & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1219869278574387200 & Wed Jan 22 06:27:54 +0000 2020 & UsaCleanup & true & $\\dots$ \\\\\n",
       "\t2 & 1219871372182245400 & Wed Jan 22 06:36:13 +0000 2020 & innovationville & false & $\\dots$ \\\\\n",
       "\t3 & 1219875910641488000 & Wed Jan 22 06:54:15 +0000 2020 & HelsinkiOne & false & $\\dots$ \\\\\n",
       "\t4 & 1219867508041105400 & Wed Jan 22 06:20:52 +0000 2020 & ivona\\_11 & true & $\\dots$ \\\\\n",
       "\t5 & 1219868124633190400 & Wed Jan 22 06:23:19 +0000 2020 & sarahderpy & true & $\\dots$ \\\\\n",
       "\t6 & 1219872204571259000 & Wed Jan 22 06:39:32 +0000 2020 & Frankdiplomat & false & $\\dots$ \\\\\n",
       "\t7 & 1219871769269547000 & Wed Jan 22 06:37:48 +0000 2020 & evaArtemise97 & false & $\\dots$ \\\\\n",
       "\t8 & 1219871144649556000 & Wed Jan 22 06:35:19 +0000 2020 & Johanisms & true & $\\dots$ \\\\\n",
       "\t9 & 1219872618787946500 & Wed Jan 22 06:41:11 +0000 2020 & RedMystique & true & $\\dots$ \\\\\n",
       "\t10 & 1219874436544811000 & Wed Jan 22 06:48:24 +0000 2020 & psybrspcsuprstr & true & $\\dots$ \\\\\n",
       "\t11 & 1219868954887254000 & Wed Jan 22 06:26:37 +0000 2020 & gingin21 & true & $\\dots$ \\\\\n",
       "\t12 & 1219868329738932200 & Wed Jan 22 06:24:08 +0000 2020 & Amsterdam2030 & true & $\\dots$ \\\\\n",
       "\t13 & 1219876426071052300 & Wed Jan 22 06:56:18 +0000 2020 & DOCisChief & false & $\\dots$ \\\\\n",
       "\t14 & 1219868138197487600 & Wed Jan 22 06:23:22 +0000 2020 & BiteOfAMosquito & true & $\\dots$ \\\\\n",
       "\t15 & 1219874441200455700 & Wed Jan 22 06:48:25 +0000 2020 & wholesomebutter & true & $\\dots$ \\\\\n",
       "\t16 & 1219872782118457300 & Wed Jan 22 06:41:50 +0000 2020 & FlatplaneJayne & true & $\\dots$ \\\\\n",
       "\t17 & 1219870288621342700 & Wed Jan 22 06:31:55 +0000 2020 & STD\\_Jonathan & true & $\\dots$ \\\\\n",
       "\t18 & 1219873889896915000 & Wed Jan 22 06:46:14 +0000 2020 & GadflySquared & true & $\\dots$ \\\\\n",
       "\t19 & 1219869064732008400 & Wed Jan 22 06:27:03 +0000 2020 & ParaSeoul & true & $\\dots$ \\\\\n",
       "\t20 & 1219871720561107000 & Wed Jan 22 06:37:36 +0000 2020 & BOSSleidyx3 & true & $\\dots$ \\\\\n",
       "\t21 & 1219869917203325000 & Wed Jan 22 06:30:27 +0000 2020 & akuma\\_river & false & $\\dots$ \\\\\n",
       "\t22 & 1219873652780556300 & Wed Jan 22 06:45:17 +0000 2020 & MountAirMedia & true & $\\dots$ \\\\\n",
       "\t23 & 1219867554451284000 & Wed Jan 22 06:21:03 +0000 2020 & 999Hawks & true & $\\dots$ \\\\\n",
       "\t24 & 1219872044302684200 & Wed Jan 22 06:38:54 +0000 2020 & AnnMarieMck & true & $\\dots$ \\\\\n",
       "\t25 & 1219868889032593400 & Wed Jan 22 06:26:21 +0000 2020 & jolenedurbin & false & $\\dots$ \\\\\n",
       "\t26 & 1219868004269338600 & Wed Jan 22 06:22:50 +0000 2020 & DarlinNathaniel & false & $\\dots$ \\\\\n",
       "\t27 & 1219874488227070000 & Wed Jan 22 06:48:36 +0000 2020 & BarbaraEEllison & false & $\\dots$ \\\\\n",
       "\t28 & 1219869910580519000 & Wed Jan 22 06:30:25 +0000 2020 & MrBenDover5 & true & $\\dots$ \\\\\n",
       "\t29 & 1219870503315230700 & Wed Jan 22 06:32:46 +0000 2020 & mandy77975978 & true & $\\dots$ \\\\\n",
       "\t30 & 1219870616590999600 & Wed Jan 22 06:33:13 +0000 2020 & Roderic20444823 & true & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "2847×7 DataFrame. Omitted printing of 5 columns\n",
       "│ Row  │ ID                  │ Created_at                     │\n",
       "│      │ \u001b[90mInt64\u001b[39m               │ \u001b[90mString\u001b[39m                         │\n",
       "├──────┼─────────────────────┼────────────────────────────────┤\n",
       "│ 1    │ 1219869278574387200 │ Wed Jan 22 06:27:54 +0000 2020 │\n",
       "│ 2    │ 1219871372182245400 │ Wed Jan 22 06:36:13 +0000 2020 │\n",
       "│ 3    │ 1219875910641488000 │ Wed Jan 22 06:54:15 +0000 2020 │\n",
       "│ 4    │ 1219867508041105400 │ Wed Jan 22 06:20:52 +0000 2020 │\n",
       "│ 5    │ 1219868124633190400 │ Wed Jan 22 06:23:19 +0000 2020 │\n",
       "│ 6    │ 1219872204571259000 │ Wed Jan 22 06:39:32 +0000 2020 │\n",
       "│ 7    │ 1219871769269547000 │ Wed Jan 22 06:37:48 +0000 2020 │\n",
       "│ 8    │ 1219871144649556000 │ Wed Jan 22 06:35:19 +0000 2020 │\n",
       "│ 9    │ 1219872618787946500 │ Wed Jan 22 06:41:11 +0000 2020 │\n",
       "│ 10   │ 1219874436544811000 │ Wed Jan 22 06:48:24 +0000 2020 │\n",
       "⋮\n",
       "│ 2837 │ 1219940602210672600 │ Wed Jan 22 11:11:19 +0000 2020 │\n",
       "│ 2838 │ 1219941497988173800 │ Wed Jan 22 11:14:53 +0000 2020 │\n",
       "│ 2839 │ 1219941515667157000 │ Wed Jan 22 11:14:57 +0000 2020 │\n",
       "│ 2840 │ 1219939708307824600 │ Wed Jan 22 11:07:46 +0000 2020 │\n",
       "│ 2841 │ 1219939133251960800 │ Wed Jan 22 11:05:29 +0000 2020 │\n",
       "│ 2842 │ 1219938961562525700 │ Wed Jan 22 11:04:48 +0000 2020 │\n",
       "│ 2843 │ 1219941493932204000 │ Wed Jan 22 11:14:52 +0000 2020 │\n",
       "│ 2844 │ 1219940448300687400 │ Wed Jan 22 11:10:42 +0000 2020 │\n",
       "│ 2845 │ 1219940573416693800 │ Wed Jan 22 11:11:12 +0000 2020 │\n",
       "│ 2846 │ 1219937771021750300 │ Wed Jan 22 11:00:04 +0000 2020 │\n",
       "│ 2847 │ 1219939100666536000 │ Wed Jan 22 11:05:21 +0000 2020 │"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV (3 columns are not shown) directly into dataframe\n",
    "example_df = DataFrame(CSV.File(\"ExampleCSV.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5×7 DataFrame\n",
      "│ Row │ ID                  │ Created_at                     │ USER            │\n",
      "│     │ \u001b[90mInt64\u001b[39m               │ \u001b[90mString\u001b[39m                         │ \u001b[90mString\u001b[39m          │\n",
      "├─────┼─────────────────────┼────────────────────────────────┼─────────────────┤\n",
      "│ 1   │ 1219869278574387200 │ Wed Jan 22 06:27:54 +0000 2020 │ UsaCleanup      │\n",
      "│ 2   │ 1219871372182245400 │ Wed Jan 22 06:36:13 +0000 2020 │ innovationville │\n",
      "│ 3   │ 1219875910641488000 │ Wed Jan 22 06:54:15 +0000 2020 │ HelsinkiOne     │\n",
      "│ 4   │ 1219867508041105400 │ Wed Jan 22 06:20:52 +0000 2020 │ ivona_11        │\n",
      "│ 5   │ 1219868124633190400 │ Wed Jan 22 06:23:19 +0000 2020 │ sarahderpy      │\n",
      "\n",
      "│ Row │ Is_Retweet │ RT_User │ RT_Id               │\n",
      "│     │ \u001b[90mBool\u001b[39m       │ \u001b[90mString\u001b[39m  │ \u001b[90mInt64\u001b[39m               │\n",
      "├─────┼────────────┼─────────┼─────────────────────┤\n",
      "│ 1   │ true       │ Reuters │ 1219854705330999300 │\n",
      "│ 2   │ false      │ 0       │ 0                   │\n",
      "│ 3   │ false      │ 0       │ 0                   │\n",
      "│ 4   │ true       │ CDCgov  │ 1219725632906694700 │\n",
      "│ 5   │ true       │ CNN     │ 1219857995632386000 │\n",
      "\n",
      "│ Row │ Hashtags                         │\n",
      "│     │ \u001b[90mString\u001b[39m                           │\n",
      "├─────┼──────────────────────────────────┤\n",
      "│ 1   │ 0                                │\n",
      "│ 2   │ 0                                │\n",
      "│ 3   │ Any[\"coronavirus\", \"WHO\", \"CDC\"] │\n",
      "│ 4   │ Any[\"coronavirus\"]               │\n",
      "│ 5   │ 0                                │"
     ]
    }
   ],
   "source": [
    "# Show first 5 rows with all columns \n",
    "show(first(example_df,5), allcols=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check format of the Hashtag Arrays \n",
    "typeof(example_df.Hashtags[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Any,1}:\n",
       " \"sb276\"       \n",
       " \"vaccinetruth\"\n",
       " \"vaccines\"    "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse Hashtag entry from String to Array  \n",
    "eval(Meta.parse(example_df.Hashtags[9])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse whole Hashtag column back to array \n",
    "example_df.Hashtags = eval.(Meta.parse.(example_df.Hashtags[1:end]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Any,1}:\n",
       " \"sb276\"       \n",
       " \"vaccinetruth\"\n",
       " \"vaccines\"    "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check cleaned column\n",
    "example_df.Hashtags[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the \"Created_at\" column and sort it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful package \n",
    "using Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wed Jan 22 06:27:54 +0000 2020\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check previous date format\n",
    "example_df.Created_at[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the dates to read it easily with the Dates.pkg and safe it in the dataframe\n",
    "example_df.Created_at = Dates.DateTime.(example_df.Created_at, \"e u dd HH:MM:SS +0000 yyyy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 22 06:00:00 +0000 2020\n",
      "Wed Jan 22 11:59:56 +0000 2020\n"
     ]
    }
   ],
   "source": [
    "# Sort array by date column \n",
    "df_sorted = sort(df, order(:Created_at));\n",
    "# Print first and last date \n",
    "println(df_sorted.Created_at[1])\n",
    "println(df_sorted.Created_at[end])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
